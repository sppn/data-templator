{
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "dbutils.widgets.text(\"filename\", \"\",\"\")\ndbutils.widgets.get(\"filename\")\nfilename = getArgument(\"filename\")\nprint (\"Param -\\'input':\")\nprint (filename)\nspark.conf.set(\"dfs.adls.oauth2.access.token.provider.type\", \"ClientCredential\")\nspark.conf.set(\"dfs.adls.oauth2.client.id\", \"{{ source.client_id }}\")\nspark.conf.set(\"dfs.adls.oauth2.credential\", \"{{ source.client_credential }}\")\nspark.conf.set(\"dfs.adls.oauth2.refresh.url\", \"https://login.microsoftonline.com/{{source.tenant_id}}/oauth2/token \")"
            ],
            "metadata": {},
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "raw_folder = \"{{ source.raw_folder }}\"\ninfile = \"/Raw/{{ source.raw_folder }}/\" + filename\n\nsdf = spark.read.option(\"delimiter\", \"{{ source.delimiter }}\").csv(\"adl://{{ source.datalakestore_accountname }}.azuredatalakestore.net/\" + infile, quote='\"', escape='\"', header=True)\nsdf.createOrReplaceTempView(\"myRecords\")"
            ],
            "metadata": {},
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "sdf = spark.sql(\"\"\"\nSELECT \n{{#source.date_columns}}to_utc_timestamp(CAST(UNIX_TIMESTAMP(`{{name}}`, \"{{ source.date_format }}\") AS TIMESTAMP), '{{source.date_locale}}') AS `{{name_without_spaces}}_UTC`,\n{{/source.date_columns}}{{#columns}}\tTRIM(m.`{{name}}`) as `{{name_without_spaces}}`,\n {{/columns}}\n\tcurrent_timestamp() AS run_date_utc\n   FROM myRecords AS m\n\"\"\")\nsdf.createOrReplaceTempView(\"sdf\")"
            ],
            "metadata": {},
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source":["%sql\n--DL3\n-- {{ target.database }}_master.{{ source.database}}_{{ template_config.variables.source_tablename_formatted }} = Table in master to update\n-- {{target.database}}_master.{{source.database}}_{{source.tablename}}_new = Table containing update/inserts for above table (assuming it is in memory and column names and data types match)\n-- <Rowname> = Matching rowname from the master table\n\n\n--Make a table to hold result data \ndrop table if exists {{target.database}}_master.{{source.database}}_{{source.tablename}}_new;\ncreate table if not exists {{target.database}}_master.{{source.database}}_{{source.tablename}}_new(\n{{#source.date_columns}}\t`{{name_without_spaces}}_UTC` timestamp,\n {{/source.date_columns}}{{#columns}}\t`{{name_without_spaces}}` string{{^last}},\n {{/last}}{{/columns}},\n`run_date_utc` timestamp \n using parquet;\n\n--insert union into new table (result of updates/inserts )\nInsert into {{target.database}}_master.{{source.database}}_{{source.tablename}}_new\n--select all rows in existing table where the key is not in the new table\nSelect * from {{target.database}}_master.{{source.database}}_{{source.tablename}} as x\nleft anti join sdf t on {{#source.primary_key}}x.{{name}} = t.{{name}}{{^last}} and {{/last}}{{/source.primary_key}} \nunion \n--select all rows in the new table\nselect * from sdf;\n\n--replace existing table with update table\ndrop table if exists {{target.database}}_master.{{source.database}}_{{source.tablename}};\nalter table {{target.database}}_master.{{source.database}}_{{source.tablename}}_new rename to {{target.database}}_master.{{source.database}}_{{source.tablename}};"],
            "metadata": {},
            "outputs": [],
            "execution_count": null
        }
    ],
    "metadata": {
        "name": "R2M_DL3_{{ template_config.variables.source_tablename_formatted }}"
    },
    "nbformat": 4,
    "nbformat_minor": 0
}